{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "KYbOPKRtfQOr"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import utils\n",
    "\n",
    "from pyvirtualdisplay import Display\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.losses import MSE\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Set up a virtual display to render the Lunar Lander environment.\n",
    "Display(visible=0, size=(840, 480)).start();\n",
    "\n",
    "# Set the random seed for TensorFlow\n",
    "tf.random.set_seed(utils.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "MEMORY_SIZE = 100_000     # size of memory buffer\n",
    "GAMMA = 0.995             # discount factor\n",
    "ALPHA = 1e-3              # learning rate  \n",
    "NUM_STEPS_FOR_UPDATE = 4  # perform a learning update every C time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ILVMYKewfR0n"
   },
   "outputs": [],
   "source": [
    "env = gym.make('LunarLander-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=600x400 at 0x7F1562256490>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "PIL.Image.fromarray(env.render(mode='rgb_array'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "x3fdqdG4CUu2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Shape: (8,)\n",
      "Number of actions: 4\n"
     ]
    }
   ],
   "source": [
    "state_size = env.observation_space.shape\n",
    "num_actions = env.action_space.n\n",
    "\n",
    "print('State Shape:', state_size)\n",
    "print('Number of actions:', num_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Reset the environment and get the initial state.\n",
    "current_state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_0a258f48_bc60_11ee_9e41_0242ac12010e th {\n",
       "          border: 1px solid grey;\n",
       "          text-align: center;\n",
       "    }    #T_0a258f48_bc60_11ee_9e41_0242ac12010e tbody td {\n",
       "          border: 1px solid grey;\n",
       "          text-align: center;\n",
       "    }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow0_col0 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow1_col1 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow1_col2 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow1_col3 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow1_col4 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow1_col5 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow1_col6 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow1_col7 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow1_col8 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow1_col9 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow1_col10 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow1_col11 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow2_col0 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow3_col1 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow3_col2 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow3_col3 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow3_col4 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow3_col5 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow3_col6 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow3_col7 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow3_col8 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow3_col9 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow3_col10 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow3_col11 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow4_col1 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow4_col2 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow4_col3 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow4_col4 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow4_col5 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow4_col6 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow4_col7 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow4_col8 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow4_col9 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow4_col10 {\n",
       "            background-color :  grey;\n",
       "        }    #T_0a258f48_bc60_11ee_9e41_0242ac12010erow4_col11 {\n",
       "            background-color :  grey;\n",
       "        }</style><table id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010e\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" ></th>        <th class=\"col_heading level0 col1\" colspan=8>State Vector</th>        <th class=\"col_heading level0 col9\" colspan=3>Derived from the State Vector (the closer to zero, the better)</th>    </tr>    <tr>        <th class=\"blank level1\" ></th>        <th class=\"col_heading level1 col0\" ></th>        <th class=\"col_heading level1 col1\" colspan=2>Coordinate</th>        <th class=\"col_heading level1 col3\" colspan=2>Velocity</th>        <th class=\"col_heading level1 col5\" colspan=2>Tilting</th>        <th class=\"col_heading level1 col7\" colspan=2>Ground contact</th>        <th class=\"col_heading level1 col9\" >Distance from landing pad</th>        <th class=\"col_heading level1 col10\" >Velocity</th>        <th class=\"col_heading level1 col11\" >Tilting Angle (absolute value)</th>    </tr>    <tr>        <th class=\"blank level2\" ></th>        <th class=\"col_heading level2 col0\" ></th>        <th class=\"col_heading level2 col1\" >X (Horizontal)</th>        <th class=\"col_heading level2 col2\" >Y (Vertical)</th>        <th class=\"col_heading level2 col3\" >X (Horizontal)</th>        <th class=\"col_heading level2 col4\" >Y (Vertical)</th>        <th class=\"col_heading level2 col5\" >Angle</th>        <th class=\"col_heading level2 col6\" >Angular Velocity</th>        <th class=\"col_heading level2 col7\" >Left Leg?</th>        <th class=\"col_heading level2 col8\" >Right Leg?</th>        <th class=\"col_heading level2 col9\" ></th>        <th class=\"col_heading level2 col10\" ></th>        <th class=\"col_heading level2 col11\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010elevel0_row0\" class=\"row_heading level0 row0\" >Current State</th>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow0_col0\" class=\"data row0 col0\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow0_col1\" class=\"data row0 col1\" >0.001919</td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow0_col2\" class=\"data row0 col2\" >1.422301</td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow0_col3\" class=\"data row0 col3\" >0.194400</td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow0_col4\" class=\"data row0 col4\" >0.505814</td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow0_col5\" class=\"data row0 col5\" >-0.002217</td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow0_col6\" class=\"data row0 col6\" >-0.044034</td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow0_col7\" class=\"data row0 col7\" >False</td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow0_col8\" class=\"data row0 col8\" >False</td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow0_col9\" class=\"data row0 col9\" >1.422302</td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow0_col10\" class=\"data row0 col10\" >0.541885</td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow0_col11\" class=\"data row0 col11\" >0.002217</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010elevel0_row1\" class=\"row_heading level0 row1\" >Action</th>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow1_col0\" class=\"data row1 col0\" >Do nothing</td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow1_col1\" class=\"data row1 col1\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow1_col2\" class=\"data row1 col2\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow1_col3\" class=\"data row1 col3\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow1_col4\" class=\"data row1 col4\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow1_col5\" class=\"data row1 col5\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow1_col6\" class=\"data row1 col6\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow1_col7\" class=\"data row1 col7\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow1_col8\" class=\"data row1 col8\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow1_col9\" class=\"data row1 col9\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow1_col10\" class=\"data row1 col10\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow1_col11\" class=\"data row1 col11\" ></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010elevel0_row2\" class=\"row_heading level0 row2\" >Next State</th>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow2_col0\" class=\"data row2 col0\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow2_col1\" class=\"data row2 col1\" >0.003839</td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow2_col2\" class=\"data row2 col2\" >1.433103</td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow2_col3\" class=\"data row2 col3\" >0.194137</td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow2_col4\" class=\"data row2 col4\" >0.480094</td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow2_col5\" class=\"data row2 col5\" >-0.004393</td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow2_col6\" class=\"data row2 col6\" >-0.043519</td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow2_col7\" class=\"data row2 col7\" >False</td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow2_col8\" class=\"data row2 col8\" >False</td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow2_col9\" class=\"data row2 col9\" >1.433108</td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow2_col10\" class=\"data row2 col10\" >0.517860</td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow2_col11\" class=\"data row2 col11\" >0.004393</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010elevel0_row3\" class=\"row_heading level0 row3\" >Reward</th>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow3_col0\" class=\"data row3 col0\" >1.104326</td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow3_col1\" class=\"data row3 col1\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow3_col2\" class=\"data row3 col2\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow3_col3\" class=\"data row3 col3\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow3_col4\" class=\"data row3 col4\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow3_col5\" class=\"data row3 col5\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow3_col6\" class=\"data row3 col6\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow3_col7\" class=\"data row3 col7\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow3_col8\" class=\"data row3 col8\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow3_col9\" class=\"data row3 col9\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow3_col10\" class=\"data row3 col10\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow3_col11\" class=\"data row3 col11\" ></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010elevel0_row4\" class=\"row_heading level0 row4\" >Episode Terminated</th>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow4_col0\" class=\"data row4 col0\" >False</td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow4_col1\" class=\"data row4 col1\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow4_col2\" class=\"data row4 col2\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow4_col3\" class=\"data row4 col3\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow4_col4\" class=\"data row4 col4\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow4_col5\" class=\"data row4 col5\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow4_col6\" class=\"data row4 col6\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow4_col7\" class=\"data row4 col7\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow4_col8\" class=\"data row4 col8\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow4_col9\" class=\"data row4 col9\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow4_col10\" class=\"data row4 col10\" ></td>\n",
       "                        <td id=\"T_0a258f48_bc60_11ee_9e41_0242ac12010erow4_col11\" class=\"data row4 col11\" ></td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f15802e2a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select an action\n",
    "action = 0\n",
    "\n",
    "# Run a single time step of the environment's dynamics with the given action.\n",
    "next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "# Display table with values.\n",
    "utils.display_table(current_state, action, next_state, reward, done)\n",
    "\n",
    "# Replace the `current_state` with the state after the action is taken\n",
    "current_state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# UNQ_C1\n",
    "# GRADED CELL\n",
    "\n",
    "# Create the Q-Network\n",
    "q_network = Sequential([\n",
    "    ### START CODE HERE ### \n",
    "    Input(shape=state_size),\n",
    "    tf.keras.layers.Dense(64,activation='relu'),\n",
    "    tf.keras.layers.Dense(64,activation='relu'),\n",
    "    tf.keras.layers.Dense(num_actions,activation='linear')\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### END CODE HERE ### \n",
    "    ])\n",
    "\n",
    "# Create the target Q^-Network\n",
    "target_q_network = Sequential([\n",
    "    ### START CODE HERE ### \n",
    "    Input(shape=state_size),\n",
    "    tf.keras.layers.Dense(64,activation='relu'),\n",
    "    tf.keras.layers.Dense(64,activation='relu'),\n",
    "    tf.keras.layers.Dense(num_actions,activation='linear')\n",
    "  \n",
    "    ### END CODE HERE ###\n",
    "    ])\n",
    "\n",
    "### START CODE HERE ### \n",
    "optimizer = Adam(learning_rate=ALPHA)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAll tests passed!\n",
      "\u001b[92mAll tests passed!\n",
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "# UNIT TEST\n",
    "from public_tests import *\n",
    "\n",
    "test_network(q_network)\n",
    "test_network(target_q_network)\n",
    "test_optimizer(optimizer, ALPHA) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Store experiences as named tuples\n",
    "experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# UNQ_C2\n",
    "# GRADED FUNCTION: calculate_loss\n",
    "\n",
    "def compute_loss(experiences, gamma, q_network, target_q_network):\n",
    "    \"\"\" \n",
    "    Calculates the loss.\n",
    "    \n",
    "    Args:\n",
    "      experiences: (tuple) tuple of [\"state\", \"action\", \"reward\", \"next_state\", \"done\"] namedtuples\n",
    "      gamma: (float) The discount factor.\n",
    "      q_network: (tf.keras.Sequential) Keras model for predicting the q_values\n",
    "      target_q_network: (tf.keras.Sequential) Keras model for predicting the targets\n",
    "          \n",
    "    Returns:\n",
    "      loss: (TensorFlow Tensor(shape=(0,), dtype=int32)) the Mean-Squared Error between\n",
    "            the y targets and the Q(s,a) values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Unpack the mini-batch of experience tuples\n",
    "    states, actions, rewards, next_states, done_vals = experiences\n",
    "    \n",
    "    # Compute max Q^(s,a)\n",
    "    max_qsa = tf.reduce_max(target_q_network(next_states), axis=-1)\n",
    "    \n",
    "    # Set y = R if episode terminates, otherwise set y = R + γ max Q^(s,a).\n",
    "    ### START CODE HERE ### \n",
    "    y_targets = None\n",
    "   \n",
    "    y_targets=rewards+(gamma)*(1-done_vals)*(max_qsa)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Get the q_values and reshape to match y_targets\n",
    "    q_values = q_network(states)\n",
    "    q_values = tf.gather_nd(q_values, tf.stack([tf.range(q_values.shape[0]),\n",
    "                                                tf.cast(actions, tf.int32)], axis=1))\n",
    "        \n",
    "    # Compute the loss\n",
    "    ### START CODE HERE ### \n",
    "    loss = MSE(y_targets,q_values)\n",
    "    ### END CODE HERE ### \n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "# UNIT TEST    \n",
    "test_compute_loss(compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def agent_learn(experiences, gamma):\n",
    "    \"\"\"\n",
    "    Updates the weights of the Q networks.\n",
    "    \n",
    "    Args:\n",
    "      experiences: (tuple) tuple of [\"state\", \"action\", \"reward\", \"next_state\", \"done\"] namedtuples\n",
    "      gamma: (float) The discount factor.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the loss\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(experiences, gamma, q_network, target_q_network)\n",
    "\n",
    "    # Get the gradients of the loss with respect to the weights.\n",
    "    gradients = tape.gradient(loss, q_network.trainable_variables)\n",
    "    \n",
    "    # Update the weights of the q_network.\n",
    "    optimizer.apply_gradients(zip(gradients, q_network.trainable_variables))\n",
    "\n",
    "    # update the weights of target q_network\n",
    "    utils.update_target_network(q_network, target_q_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "num_episodes = 2000\n",
    "max_num_timesteps = 1000\n",
    "\n",
    "total_point_history = []\n",
    "\n",
    "num_p_av = 100    # number of total points to use for averaging\n",
    "epsilon = 1.0     # initial ε value for ε-greedy policy\n",
    "\n",
    "# Create a memory buffer D with capacity N\n",
    "memory_buffer = deque(maxlen=MEMORY_SIZE)\n",
    "\n",
    "# Set the target network weights equal to the Q-Network weights\n",
    "target_q_network.set_weights(q_network.get_weights())\n",
    "\n",
    "for i in range(num_episodes):\n",
    "    \n",
    "    # Reset the environment to the initial state and get the initial state\n",
    "    state = env.reset()\n",
    "    total_points = 0\n",
    "    \n",
    "    for t in range(max_num_timesteps):\n",
    "        \n",
    "        # From the current state S choose an action A using an ε-greedy policy\n",
    "        state_qn = np.expand_dims(state, axis=0)  # state needs to be the right shape for the q_network\n",
    "        q_values = q_network(state_qn)\n",
    "        action = utils.get_action(q_values, epsilon)\n",
    "        \n",
    "        # Take action A and receive reward R and the next state S'\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        # Store experience tuple (S,A,R,S') in the memory buffer.\n",
    "        # We store the done variable as well for convenience.\n",
    "        memory_buffer.append(experience(state, action, reward, next_state, done))\n",
    "        \n",
    "        # Only update the network every NUM_STEPS_FOR_UPDATE time steps.\n",
    "        update = utils.check_update_conditions(t, NUM_STEPS_FOR_UPDATE, memory_buffer)\n",
    "        \n",
    "        if update:\n",
    "            # Sample random mini-batch of experience tuples (S,A,R,S') from D\n",
    "            experiences = utils.get_experiences(memory_buffer)\n",
    "            \n",
    "            # Set the y targets, perform a gradient descent step,\n",
    "            # and update the network weights.\n",
    "            agent_learn(experiences, GAMMA)\n",
    "        \n",
    "        state = next_state.copy()\n",
    "        total_points += reward\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "    total_point_history.append(total_points)\n",
    "    av_latest_points = np.mean(total_point_history[-num_p_av:])\n",
    "    \n",
    "    # Update the ε value\n",
    "    epsilon = utils.get_new_eps(epsilon)\n",
    "\n",
    "    print(f\"\\rEpisode {i+1} | Total point average of the last {num_p_av} episodes: {av_latest_points:.2f}\", end=\"\")\n",
    "\n",
    "    if (i+1) % num_p_av == 0:\n",
    "        print(f\"\\rEpisode {i+1} | Total point average of the last {num_p_av} episodes: {av_latest_points:.2f}\")\n",
    "\n",
    "    # We will consider that the environment is solved if we get an\n",
    "    # average of 200 points in the last 100 episodes.\n",
    "    if av_latest_points >= 200.0:\n",
    "        print(f\"\\n\\nEnvironment solved in {i+1} episodes!\")\n",
    "        q_network.save('lunar_lander_model.h5')\n",
    "        break\n",
    "        \n",
    "tot_time = time.time() - start\n",
    "\n",
    "print(f\"\\nTotal Runtime: {tot_time:.2f} s ({(tot_time/60):.2f} min)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "E_EUXxurfe8m",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the total point history along with the moving average\n",
    "utils.plot_history(total_point_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Suppress warnings from imageio\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "3Ttb_zLeJKiG"
   },
   "outputs": [],
   "source": [
    "filename = \"./videos/lunar_lander.mp4\"\n",
    "\n",
    "utils.create_video(filename, env, q_network)\n",
    "utils.embed_mp4(filename)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TensorFlow - Lunar Lander.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
